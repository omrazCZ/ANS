---
title: "Sports Network"
output: html_document
---

## Packages

```{r message=FALSE, warning=FALSE}
library(compiler)
library(dplyr)
library(tidygraph)
library(ggraph)
library(tidyverse)
library(sna)
library(igraph)
library(visNetwork)
library(networkD3)
```

## Import network data

The dataset has two dataframes that we can use to get the information about nodes and the information about edges. We rename the columns of the matchup dataframe to fit the edges definition and we have an id to the lineup dataframe to refer to lineup players by their node id.

The original dataset of matchups has lineups numbered from zero, but tidygraph (and most packages in R) have indices that start in 1. For that we add 1 to the entries of the edges table and also to lineup dable.
```{r message=FALSE, warning=FALSE}
lineup <- read_csv("lineups.csv")
lineup$id <- lineup$id +1 
names(lineup) <- c('id','label','team')

matchups <- read_csv("matchups.csv")
matchup <- matchups[,c("home_players","away_players","type","weight","home_team","away_team","time")]
names(matchup) <- c('from','to','weight','score',"home_team","away_team","time")
matchup$to <- matchup$to+1
matchup$from <- matchup$from+1
matchup <- matchup[!(matchup$weight==0),]


#consider time effect
matchup$score_adjusted <- matchup$score/matchup$time 

matchup$weight <- factor(matchup$weight)

print(paste("# Lineups: ",nrow(lineup)))
print(paste("# Matchups: ",nrow(matchups)))
print(paste("# Matchups after filtering: ",nrow(matchup),"(differences:",nrow(matchups)-nrow(matchup),")"))


```


Train-test sets split

```{r message=FALSE, warning=FALSE}
pairs <- matchup %>% distinct(from, to, .keep_all = F)
print(paste("pairs: ", nrow(pairs)))

train_pairs <- pairs[1:floor(0.8*nrow(pairs)),,] %>% mutate(pair = mapply(c, from, to, SIMPLIFY  = F))
print(paste("train pairs: ",nrow(train_pairs)))

matchup <- matchup %>% mutate(pair = mapply(c, from, to, SIMPLIFY  = F))
matchup$split <- list(matchup$pair)[[1]] %in% list(train_pairs$pair)[[1]]
print(paste("train edges: ", sum(matchup$split)))

matchup_train <- matchup[matchup$split,]
```

## Create network

Now both dataframes are ready to build a graph. With the function tbl_graph, we can use both dataframes, telling it to build an directed network with the parameter directed set to TRUE:
```{r}
basenet <- tbl_graph(nodes = lineup, edges = matchup_train, directed = T,node_key = "label")
basenet
```
As you can see, the result has a nodes part with the name of lineup players and their node id. The edges have endpoints in the columns "to" and "from" and a weight column that gives the results of the matchups.


Furthermore, we can calculate the degree centrality of each node. Since we have 4 cases for each node: positive in edge, positive out edge, negative in edge, negative in edge, the degree will also have 4 versions corresponding to each case.  
```{r warning=FALSE}
 pdegree <- basenet %>% 
  activate(edges) %>% filter(weight == 1) %>%
  activate(nodes) %>%
  mutate(
    Pin = centrality_degree(mode = "in"),
    Pout = centrality_degree(mode = "out")
  )  %>%
  as_tibble()

ndegree <- basenet %>% activate(edges) %>% filter(weight == -1) %>%
  activate(nodes) %>%
  mutate(
    Nin = centrality_degree(mode = "in"),
    Nout = centrality_degree(mode = "out"),
#   degree = centrality_degree(mode = "all")
  ) %>%
  as_tibble()

new_lineup <- inner_join(pdegree,ndegree,by=c("id","label","team"))
```

Total in/out degree for each node is as follows:
```{r}
basenet %>% 
  activate(nodes) %>%
  mutate(
    in_degree = centrality_degree(mode = "in"),
    out_degree = centrality_degree(mode = "out"),
    degree = centrality_degree(mode = "all")
  ) %>%
  as_tibble()
```
Shortest path between each pair of nodes:
Could try different ways to get shortest path
```{r warning=FALSE}
distances(
  basenet,
  v = V(basenet)[id==1], 
  to=V(basenet)[id==3],
  mode = "all",
  weights = NULL,
  algorithm = "automatic"
)
```




An example to calculate shortest path.
```{r}
el <- matrix(ncol=3, byrow=TRUE,
             c(2,1,1,2,4,1,1,3,-1,3,4,-1) )
print(el)
g2 <- add_edges(make_empty_graph(4), t(el[,1:2]), weight=el[,3])
vertex_attr(g2) <- list(name = LETTERS[1:4],
                        color = rep("yellow", gorder(g2)))
vertex_attr(g2, "label") <- V(g2)$name
plot(g2)
distances(g2,v=1, to=2,mode="in") #from 2 all pointed to 1
distances(g2,v=1, to=2,mode="out") #from 1 all pointed to 2
distances(g2,v=1, to=2,mode="all") #direction of edges ignored
```




Define a dataframe to store ISM features. 
```{r warning=FALSE}

edge_centric <- data.frame(node1=numeric(), node2=numeric(),
                           Pin_Pout=numeric(), Pin_Nout=numeric(), Nin_Pout=numeric(), Nin_Nout=numeric(),
                           Pin_Pin=numeric(), Pin_Nin=numeric(), Nin_Pin=numeric(), Nin_Nin=numeric(),
                           Pout_Pin=numeric(), Pout_Nin=numeric(), Nout_Pin=numeric(), Nout_Nin=numeric(),
                           Pout_Pout=numeric(), Pout_Nout=numeric(), Nout_Pout=numeric(), Nout_Nout=numeric(),
                           stringsAsFactors=FALSE) 

```


```{r}
# input
name_list <- names(edge_centric)[3:18] 

# mapping
map <- c(
  "Pin_Pout" = c(1,1), "Pin_Nout" = c(1,-1), "Nin_Pout" = c(-1,1), "Nin_Nout" = c(-1,-1),
  "Pin_Pin"= c(1,1),    "Pin_Nin"= c(1,-1),    "Nin_Pin"= c(-1,1),  "Nin_Nin"= c(-1,-1),   
  "Pout_Pin"= c(1,1),   "Pout_Nin"= c(1,-1),   "Nout_Pin"= c(-1,1),  "Nout_Nin"= c(-1,-1),
  "Pout_Pout"= c(1,1),  "Pout_Nout"= c(1,-1),  "Nout_Pout"= c(-1,1), "Nout_Nout"= c(-1,-1)
  )

 map[paste(name_list[1],1,sep="")] 
 map[paste(name_list[1],2,sep="")]
```


```{r}
# Calculate shortest (directed) paths
DistsDir <- data.frame(matrix(NA, nrow = nrow(pairs), ncol = 18))
colnames(DistsDir) <- colnames(edge_centric)
DistsDir$node1 <- pairs$from
DistsDir$node2 <- pairs$to

print(nrow(DistsDir))
for (row in c(1:nrow(DistsDir))){#row <- 1
  
  if (row %% 100 == 0){
    print(row)
  }
  
  i <- pairs$from[[row]]
  j <- pairs$to[[row]]
  
  for (k in c(1:4)){
    weight1 <- map[paste(name_list[k],1,sep="")] 
    weight2 <- map[paste(name_list[k],2,sep="")]
    temp_edge <- matchup_train[((matchup_train$to==i & matchup_train$weight==weight1 ) | (matchup_train$from==j & matchup_train$weight==weight2) | (matchup_train$from != i & matchup_train$from != j & matchup_train$to != i & matchup_train$to != j)),]
    temp_net <- tbl_graph(nodes = new_lineup, edges = temp_edge, directed = T,node_key = "label")
    LSP <- distances(temp_net, v=V(temp_net)[id==i], to=V(temp_net)[id==j], mode="in")
    if (LSP == Inf){
      LSP <- distances(temp_net, v=V(temp_net)[id==i], to=V(temp_net)[id==j], mode="all")
    }
    DistsDir[row, name_list[k]] <- LSP
  }
  
  for (k in c(5:8)){
    weight1 <- map[paste(name_list[k],1,sep="")] 
    weight2 <- map[paste(name_list[k],2,sep="")]
    temp_edge <- matchup_train[((matchup_train$to==i & matchup_train$weight==weight1 ) | (matchup_train$to==j & matchup_train$weight==weight2) | (matchup_train$from != i & matchup_train$from != j & matchup_train$to != i & matchup_train$to != j)),]
    temp_net <- tbl_graph(nodes = new_lineup, edges = temp_edge, directed = T,node_key = "label")
    LSP <- distances(temp_net, v=V(temp_net)[id==i], to=V(temp_net)[id==j], mode="all")
    DistsDir[row, name_list[k]] <- LSP
  }
  
  for (k in c(9:12)){
    weight1 <- map[paste(name_list[k],1,sep="")] 
    weight2 <- map[paste(name_list[k],2,sep="")]
    temp_edge <- matchup_train[((matchup_train$from==i & matchup_train$weight==weight1 ) | (matchup_train$to==j & matchup_train$weight==weight2) | (matchup_train$from != i & matchup_train$from != j & matchup_train$to != i & matchup_train$to != j)),]
    temp_net <- tbl_graph(nodes = new_lineup, edges = temp_edge, directed = T,node_key = "label")
    LSP <- distances(temp_net, v=V(temp_net)[id==i], to=V(temp_net)[id==j], mode="out")
    if (LSP == Inf){
      LSP <- distances(temp_net, v=V(temp_net)[id==i], to=V(temp_net)[id==j], mode="all")
    }
    DistsDir[row, name_list[k]] <- LSP
  }
  
  for (k in c(13:16)){
    weight1 <- map[paste(name_list[k],1,sep="")] 
    weight2 <- map[paste(name_list[k],2,sep="")]
    temp_edge <- matchup_train[((matchup_train$from==i & matchup_train$weight==weight1 ) | (matchup_train$from==j & matchup_train$weight==weight2) | (matchup_train$from != i & matchup_train$from != j & matchup_train$to != i & matchup_train$to != j)),]
    temp_net <- tbl_graph(nodes = new_lineup, edges = temp_edge, directed = T,node_key = "label")
    LSP <- distances(temp_net, v=V(temp_net)[id==i], to=V(temp_net)[id==j], mode="all")
    DistsDir[row, name_list[k]] <- LSP
  }

  
}

write.csv(DistsDir, "new_results/Time_Series_DistsDir.csv", row.names = F)

```

```{r}
# Repeat for undirected paths
DistsUndir <- data.frame(matrix(NA, nrow = nrow(pairs), ncol = 18))
colnames(DistsUndir) <- colnames(edge_centric)
DistsUndir$node1 <- pairs$from
DistsUndir$node2 <- pairs$to

print(nrow(DistsUndir))
for (row in c(1:nrow(DistsUndir))){
  
  if (row %% 100 == 0){
    print(row)
  }
  
  i <- pairs$from[[row]]
  j <- pairs$to[[row]]
  
  for (k in c(1:4)){
    weight1 <- map[paste(name_list[k],1,sep="")] 
    weight2 <- map[paste(name_list[k],2,sep="")]
    temp_edge <- matchup_train[((matchup_train$to==i & matchup_train$weight==weight1 ) | (matchup_train$from==j & matchup_train$weight==weight2) | (matchup_train$from != i & matchup_train$from != j & matchup_train$to != i & matchup_train$to != j)),]
    temp_net <- tbl_graph(nodes = new_lineup, edges = temp_edge, directed = T,node_key = "label")
    LSP <- distances(temp_net, v=V(temp_net)[id==i], to=V(temp_net)[id==j], mode="all")
    DistsUndir[row, name_list[k]] <- LSP
  }
  
  for (k in c(5:8)){
    weight1 <- map[paste(name_list[k],1,sep="")] 
    weight2 <- map[paste(name_list[k],2,sep="")]
    temp_edge <- matchup_train[((matchup_train$to==i & matchup_train$weight==weight1 ) | (matchup_train$to==j & matchup_train$weight==weight2) | (matchup_train$from != i & matchup_train$from != j & matchup_train$to != i & matchup_train$to != j)),]
    temp_net <- tbl_graph(nodes = new_lineup, edges = temp_edge, directed = T,node_key = "label")
    LSP <- distances(temp_net, v=V(temp_net)[id==i], to=V(temp_net)[id==j], mode="all")
    DistsUndir[row, name_list[k]] <- LSP
  }
  
  for (k in c(9:12)){
    weight1 <- map[paste(name_list[k],1,sep="")] 
    weight2 <- map[paste(name_list[k],2,sep="")]
    temp_edge <- matchup_train[((matchup_train$from==i & matchup_train$weight==weight1 ) | (matchup_train$to==j & matchup_train$weight==weight2) | (matchup_train$from != i & matchup_train$from != j & matchup_train$to != i & matchup_train$to != j)),]
    temp_net <- tbl_graph(nodes = new_lineup, edges = temp_edge, directed = T,node_key = "label")
    LSP <- distances(temp_net, v=V(temp_net)[id==i], to=V(temp_net)[id==j], mode="all")
    DistsUndir[row, name_list[k]] <- LSP
  }
  
  for (k in c(13:16)){
    weight1 <- map[paste(name_list[k],1,sep="")] 
    weight2 <- map[paste(name_list[k],2,sep="")]
    temp_edge <- matchup_train[((matchup_train$from==i & matchup_train$weight==weight1 ) | (matchup_train$from==j & matchup_train$weight==weight2) | (matchup_train$from != i & matchup_train$from != j & matchup_train$to != i & matchup_train$to != j)),]
    temp_net <- tbl_graph(nodes = new_lineup, edges = temp_edge, directed = T,node_key = "label")
    LSP <- distances(temp_net, v=V(temp_net)[id==i], to=V(temp_net)[id==j], mode="all")
    DistsUndir[row, name_list[k]] <- LSP
  }

  
}

write.csv(DistsUndir, "new_results/Time_Series_DistsUndir.csv", row.names = F)

```


Special cases: how to deal with the edges between i & j when filtering edges. Now if there is a positive edge pointing from A to B, then "NinPin" will still keep that edge.


```{r}
# alternative edge centric

DistsUndir <- read.csv("new_results/Time_Series_DistsUndir.csv")
DistsDir <- read.csv("new_results/Time_Series_DistsDir.csv")

edge_centric_dir <- data.frame(matrix(NA, nrow = nrow(pairs), ncol = 18))
colnames(edge_centric_dir) <- colnames(edge_centric)
edge_centric_dir$node1 <- pairs$from
edge_centric_dir$node2 <- pairs$to

edge_centric_undir <- data.frame(matrix(NA, nrow = nrow(pairs), ncol = 18))
colnames(edge_centric_undir) <- colnames(edge_centric)
edge_centric_undir$node1 <- pairs$from
edge_centric_undir$node2 <- pairs$to

for (row in c(1:nrow(pairs))){
  if (row %% 1000 == 0){
        print(row)
  }
  
  i <- edge_centric_dir$node1[row]
  j <- edge_centric_dir$node2[row]
  for (col in c(3:18)) {
    act1 <- strsplit(colnames(edge_centric_dir[col]), split = "_")[[1]][1]
    act2 <- strsplit(colnames(edge_centric_dir[col]), split = "_")[[1]][2]
    edge_centric_dir[row,col] <- new_lineup[new_lineup$id == i,][[act1]] * new_lineup[new_lineup$id == j,][[act2]] / (DistsDir[row,col]**2)
    edge_centric_undir[row,col] <- new_lineup[new_lineup$id == i,][[act1]] * new_lineup[new_lineup$id == j,][[act2]] / (DistsUndir[row,col]**2)

  }
}

write.csv(edge_centric_dir, "new_results/Time_Series_edge_centric_dir_quadratic.csv", row.names = F)
write.csv(edge_centric_undir, "new_results/Time_Series_edge_centric_undir_quadratic.csv", row.names = F)

#write.csv(edge_centric_dir, "new_results/Time_Series_edge_centric_dir_linear.csv", row.names = F)
#write.csv(edge_centric_undir, "new_results/Time_Series_edge_centric_undir_linear.csv", row.names = F)
```




# Model

Now we group multiple edges between two nodes which have the same direction by summing up the scores.  
```{r warning=FALSE}
#edge_centric_dir <- read.csv("new_results/Time_Series_edge_centric_dir_quadratic.csv")
#edge_centric_undir <- read.csv("new_results/Time_Series_edge_centric_undir_quadratic.csv")

edge_centric_dir <- read.csv("new_results/Time_Series_edge_centric_dir_linear.csv")
edge_centric_undir <- read.csv("new_results/Time_Series_edge_centric_undir_linear.csv")

print(nrow(edge_centric_dir))
print(nrow(edge_centric_undir))

# group by absolute scores
#distinct_matchup <- matchup %>% 
#  group_by(from, to) %>%                            
#  summarise(score = sum(score)) %>%
#  mutate(result = sign(score)) %>% ungroup()

# group by adjusted scores
distinct_matchup <- matchup %>% 
  group_by(from, to) %>%                            
  summarise(score_adjusted = sum(score_adjusted)) %>%
  mutate(result = sign(score_adjusted)) %>% ungroup()
```

```{r message=FALSE, warning=FALSE}
# Data
#data <- edge_centric_dir %>% inner_join(distinct_matchup,by=c("node1"="from","node2"="to"))
data <- edge_centric_undir %>% inner_join(distinct_matchup,by=c("node1"="from","node2"="to"))
data$result <- ifelse(data$result==1,"win","loss")
# Inspect the data
sample_n(data, 3)
```


Train/test split
```{r}
# Split the data into training and test set

#set.seed(1)
#training.samples <- data$result %>%   createDataPartition(p = 0.8, list = FALSE)
#train.data  <- data[training.samples, ]
#test.data <- data[-training.samples, ]

# The first 80% of matchups will be used for training, rest for testing (since we want to predict future results)
trainPrecentage <- 0.8
train.data <- data[1:floor(trainPrecentage*nrow(data)),]
test.data <- data[(floor(trainPrecentage*nrow(data))+1):nrow(data),]
```


## Model -- Logistic regression (paper's approach)
```{r warning=FALSE}
# Fit the model
set.seed(1)
model <- glm( factor(result) ~ Pin_Pout+Pin_Nout+Nin_Pout+Nin_Nout+Pin_Pin+Pin_Nin+Nin_Pin+Nin_Nin+Pout_Pin+Pout_Nin+Nout_Pin+Nout_Nin+Pout_Pout+Pout_Nout+Nout_Pout+Nout_Nout,
              data = train.data, family = binomial)
# Summarize the model
summary(model)
# Make predictions
probabilities <- model %>% predict(test.data, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "win", "loss")
# Model accuracy
mean(predicted.classes == test.data$result)
```


```{r warning=FALSE}
train.data %>%
  mutate(prob = ifelse(result == "win", 1, 0)) %>%
  ggplot(aes(Pout_Pin,prob)) +
  geom_point(alpha = 0.2) +
  geom_smooth(method = "glm", method.args = list(family = "binomial")) +
  labs(
    title = "Logistic Regression Model", 
    x = "Feature",
    y = "Probability of win"
    )
```

## SVM Model
```{r}
set.seed(1)
library(e1071)

trainDataScaled <- train.data
testDataScaled <- test.data

# Scale data into uniform interval
trainDataScaled[c(3:18)] <- scale(trainDataScaled[c(3:18)])
testDataScaled[c(3:18)] <- scale(testDataScaled[c(3:18)])

trainDataScaled$result <- ifelse(trainDataScaled$result=="win", 1, 0)
testDataScaled$result <- ifelse(testDataScaled$result=="win", 1, 0)

trainDataScaled <- replace(trainDataScaled, is.na(trainDataScaled), 0)
testDataScaled <- replace(testDataScaled, is.na(testDataScaled), 0)

```

Try different kernels
Sigmoid seems to perform best.
```{r}
kernels = c('linear', 'polynomial', 'radial', 'sigmoid')
for (i in kernels){
  set.seed(1)
  
  print(i)
  
  classifier = svm(formula = result ~ Pin_Pout+Pin_Nout+Nin_Pout+Nin_Nout+Pin_Pin+Pin_Nin+Nin_Pin+Nin_Nin+Pout_Pin+Pout_Nin+Nout_Pin+Nout_Nin+Pout_Pout+Pout_Nout+Nout_Pout+Nout_Nout,
                 data = trainDataScaled,
                 type = 'C-classification',
                 kernel = i)

  y_pred = predict(classifier, newdata = testDataScaled)
  
  print("Accuracy: ")
  print(mean(y_pred == testDataScaled$result))
}
```
## Gaussian processes - Computationally infeasible
```{r}
library(mlegp)
library(caTools) 
library(caret)  
library(kernlab)

set.seed(1)
model <- gausspr(result ~ Pin_Pout+Pin_Nout+Nin_Pout+Nin_Nout+Pin_Pin+Pin_Nin+Nin_Pin+Nin_Nin+Pout_Pin+Pout_Nin+Nout_Pin+Nout_Nin+Pout_Pout+Pout_Nout+Nout_Pout+Nout_Nout, data=trainDataScaled, kernel="vanilladot")
summary(model)

y_pred = predict(model, testDataScaled)
  
print("Gaussian Process Accuracy: ")
print(mean(y_pred == testDataScaled$result))

```

```{r}
res <- (y_pred == testDataScaled$result)

write.csv(res, "res.csv", row.names = F)



```


Try different kernels # TODO later, takes too long
```{r}
gpKernels = c("rbfdot", "vanilladot", "tanhdot", "laplacedot", "besseldot")

for (i in gpKernels){
  set.seed(1)
  
  model <- gausspr(result ~ Pin_Pout+Pin_Nout+Nin_Pout+Nin_Nout+Pin_Pin+Pin_Nin+Nin_Pin+Nin_Nin+Pout_Pin+Pout_Nin+Nout_Pin+Nout_Nin+Pout_Pout+Pout_Nout+Nout_Pout+Nout_Nout, data=trainDataScaled, kernel=i)
summary(model)

  y_pred = predict(model, testDataScaled)
  
  print("Gaussian Process Accuracy: ")
  print(mean(y_pred == testDataScaled$result))
}
```


## Random Forrests, Ensemble - In progress

```{r}
library("randomForest")

# Separate features and target
X_train <- trainDataScaled %>% 
  select(Pin_Pout,Pin_Nout,Nin_Pout,Nin_Nout,Pin_Pin,Pin_Nin,Nin_Pin,Nin_Nin,Pout_Pin,Pout_Nin,Nout_Pin,Nout_Nin,Pout_Pout,Pout_Nout,Nout_Pout,Nout_Nout)
y_train <- as.factor(trainDataScaled$result)

X_test <- testDataScaled %>% 
  select(Pin_Pout,Pin_Nout,Nin_Pout,Nin_Nout,Pin_Pin,Pin_Nin,Nin_Pin,Nin_Nin,Pout_Pin,Pout_Nin,Nout_Pin,Nout_Nin,Pout_Pout,Pout_Nout,Nout_Pout,Nout_Nout)
y_test <- as.factor(testDataScaled$result)

# Train the model 
model <- randomForest(x = X_train, y = y_train, maxnodes = 10, ntree = 10)

predictions <- predict(model, X_test)
print("Random Forrest Accuracy: ")
print(mean(predictions == y_test))

```
